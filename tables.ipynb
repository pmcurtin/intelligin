{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rlcard\n",
    "import torch\n",
    "from src import DoubleDQNAgent, ModifiedGinRummyEnv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in ./env/lib/python3.10/site-packages (0.14.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in ./env/lib/python3.10/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in ./env/lib/python3.10/site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in ./env/lib/python3.10/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in ./env/lib/python3.10/site-packages (from statsmodels) (24.0)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in ./env/lib/python3.10/site-packages (from statsmodels) (1.13.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: six in ./env/lib/python3.10/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoints from our different models. rand-rule is mixed adversary model.\n",
    "\n",
    "dqn_rand_1 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/y34n75js/devout-sweep-4/dqn_11500000.pt\"))\n",
    "dqn_rand_2 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/y34n75js/vital-sweep-4/dqn_11250000.pt\"))\n",
    "dqn_rand_3 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/y34n75js/autumn-sweep-6/dqn_11950000.pt\"))\n",
    "\n",
    "dqn_rand_rule_1 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/f4k75mzd/rural-sweep-3/dqn_11450000.pt\"))\n",
    "dqn_rand_rule_2 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/f4k75mzd/dainty-sweep-5/dqn_10850000.pt\"))\n",
    "dqn_rand_rule_3 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/f4k75mzd/radiant-sweep-6/dqn_10800000.pt\"))\n",
    "\n",
    "dqn_rule_1 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/3beipkbe/gentle-sweep-4/dqn_11900000.pt\"))\n",
    "dqn_rule_2 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/3beipkbe/worthy-sweep-5/dqn_12000019.pt\"))\n",
    "dqn_rule_1 = DoubleDQNAgent.from_checkpoint(torch.load(\"checkpoints/homegrown/3beipkbe/gentle-sweep-4/dqn_10850000.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-25 10:52:28--  https://raw.githubusercontent.com/datamllab/rlcard/master/rlcard/models/gin_rummy_rule_models.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8002::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5072 (5.0K) [text/plain]\n",
      "Saving to: ‘gin_rummy_rule_models.py’\n",
      "\n",
      "gin_rummy_rule_mode 100%[===================>]   4.95K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-04-25 10:52:28 (130 MB/s) - ‘gin_rummy_rule_models.py’ saved [5072/5072]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the rule agent needs to be downloaded from the RLCard repo, as it's inaccessible through the package\n",
    "!wget https://raw.githubusercontent.com/datamllab/rlcard/master/rlcard/models/gin_rummy_rule_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gin_rummy_rule_models import GinRummyNoviceRuleAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [[dqn_rand_1, dqn_rand_2, dqn_rand_3], [dqn_rand_rule_1, dqn_rand_rule_2, dqn_rand_rule_3], [dqn_rule_1, dqn_rule_2], [rlcard.agents.RandomAgent(num_actions=110)], [GinRummyNoviceRuleAgent()]]\n",
    "env = ModifiedGinRummyEnv({'allow_step_back': False, 'seed': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generating reward table\n",
    "from rlcard.utils import tournament\n",
    "r = []\n",
    "s = [] #rlcard.make(\"gin-rummy\")\n",
    "\n",
    "for agent in agents:\n",
    "    r_ = []\n",
    "    s_ = []\n",
    "    for adversary in agents:\n",
    "        t = 0\n",
    "        s__ = []\n",
    "        for a in agent:\n",
    "            for ad in adversary:\n",
    "                env.set_agents([a, ad])\n",
    "                t_ = tournament(env, 200)[0]\n",
    "                t += t_\n",
    "                s__.append(t_)\n",
    "        r_.append(t/(len(agent) * len(adversary)))\n",
    "        c = sms.DescrStatsW(s__).tconfint_mean()\n",
    "        s_.append((c[1]-c[0])/2)\n",
    "    r.append(r_)\n",
    "    s.append(s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22376111 -0.18334444 -0.09309167  0.16953333 -0.25426667]\n",
      " [-0.19082778 -0.16327222 -0.123825    0.13108333 -0.24296667]\n",
      " [-0.40419167 -0.39409167 -0.4497625  -0.174875   -0.4088    ]\n",
      " [-0.55688333 -0.56743333 -0.575825   -0.5222     -0.594     ]\n",
      " [ 0.08695     0.10093333  0.1472      0.18885    -0.0221    ]]\n",
      "[[0.11163221 0.10647668 0.1343987  0.05350208 0.34849142]\n",
      " [0.13768412 0.13066632 0.20723741 0.06651581 0.39447278]\n",
      " [0.06998022 0.08522962 0.03181341 0.83892717 0.13786232]\n",
      " [0.03465402 0.02851091 0.27540699        nan        nan]\n",
      " [0.16599585 0.17613055 0.09720247        nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(r))\n",
    "print(np.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env, is_training=False):\n",
    "    trajectories = [[] for _ in range(env.num_players)]\n",
    "    state, player_id = env.reset()\n",
    "\n",
    "    # Loop to play the game\n",
    "    trajectories[player_id].append(state)\n",
    "    while not env.is_over():\n",
    "        # Agent plays\n",
    "        if not is_training:\n",
    "            action, _ = env.agents[player_id].eval_step(state)\n",
    "        else:\n",
    "            action = env.agents[player_id].step(state)\n",
    "\n",
    "        # Environment steps\n",
    "        next_state, next_player_id = env.step(action, env.agents[player_id].use_raw)\n",
    "        # Save action\n",
    "        trajectories[player_id].append(action)\n",
    "\n",
    "        # Set the state and player\n",
    "        state = next_state\n",
    "        player_id = next_player_id\n",
    "\n",
    "        # Save state.\n",
    "        if not env.game.is_over():\n",
    "            trajectories[player_id].append(state)\n",
    "\n",
    "    # Add a final state to all the players\n",
    "    for player_id in range(env.num_players):\n",
    "        state = env.get_state(player_id)\n",
    "        trajectories[player_id].append(state)\n",
    "\n",
    "    # Payoffs\n",
    "    payoffs = env.get_payoffs()\n",
    "\n",
    "    return trajectories, payoffs\n",
    "\n",
    "def tournament(env, num):\n",
    "    payoffs = [0 for _ in range(env.num_players)]\n",
    "    counter = 0\n",
    "    lens = []\n",
    "    while counter < num:\n",
    "        _, _payoffs = env.run(is_training=False)\n",
    "        lens.append((len(_[0])-2)//2)\n",
    "        if isinstance(_payoffs, list):\n",
    "            for _p in _payoffs:\n",
    "                for i, _ in enumerate(payoffs):\n",
    "                    payoffs[i] += _p[i]\n",
    "                counter += 1\n",
    "        else:\n",
    "            for i, _ in enumerate(payoffs):\n",
    "                payoffs[i] += _payoffs[i]\n",
    "            counter += 1\n",
    "    for i, _ in enumerate(payoffs):\n",
    "        payoffs[i] /= counter\n",
    "    return payoffs, lens\n",
    "\n",
    "def tournament_wins(env, num):\n",
    "    # only works for environments with two agents...\n",
    "    wins = [0.0 for _ in range(env.num_players)]\n",
    "    counter = 0\n",
    "    while counter < num:\n",
    "        _, _payoffs = env.run(is_training=False)\n",
    "        if isinstance(_payoffs, list):\n",
    "            for _p in _payoffs:\n",
    "                for i, _ in enumerate(wins):\n",
    "                    wins[i] += 1 if _p[i] > p_[1-i] else 0\n",
    "                counter += 1\n",
    "        else:\n",
    "            for i, _ in enumerate(wins):\n",
    "                wins[i] += 1 if _payoffs[i] > _payoffs[1-i] else 0\n",
    "            counter += 1\n",
    "    for i, _ in enumerate(wins):\n",
    "        wins[i] /= counter\n",
    "    return wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generating episode length table\n",
    "l = []\n",
    "s = []\n",
    "\n",
    "for agent in agents:\n",
    "    l_ = []\n",
    "    s_ = []\n",
    "    for adversary in agents:\n",
    "        t = []\n",
    "        for a in agent:\n",
    "            for ad in adversary:\n",
    "                env.set_agents([a, ad])\n",
    "                _, lens = tournament(env, 200)\n",
    "                t += lens\n",
    "        l_.append(np.mean(t))\n",
    "        c = sms.DescrStatsW(t).tconfint_mean()\n",
    "        s_.append((c[1]-c[0])/2)\n",
    "    l.append(l_)\n",
    "    s.append(s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53.61611111 48.68611111 51.63666667 38.01666667 26.54833333]\n",
      " [46.635      45.30166667 55.21166667 41.91666667 28.455     ]\n",
      " [50.57       56.12416667 82.56625    66.1875     26.6525    ]\n",
      " [34.89833333 40.46666667 65.27       60.565      22.575     ]\n",
      " [26.78166667 28.07666667 28.32       25.97       25.1       ]]\n",
      "[[1.74540946 1.62216849 2.03873773 1.56376451 1.19628581]\n",
      " [1.59455009 1.48882552 2.08917081 1.89133319 1.260551  ]\n",
      " [2.01217468 2.10957815 2.23457339 2.48705883 1.46447287]\n",
      " [1.52644154 1.85976934 2.35749466 1.15860611 1.63811587]\n",
      " [1.22649454 1.19680545 1.64346541 1.83196865 1.65157369]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(l))\n",
    "print(np.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generating win-rate table\n",
    "w = []\n",
    "s = []\n",
    "\n",
    "for agent in agents:\n",
    "    l_ = []\n",
    "    s_ = []\n",
    "    for adversary in agents:\n",
    "        t = []\n",
    "        for a in agent:\n",
    "            for ad in adversary:\n",
    "                env.set_agents([a, ad])\n",
    "                wins = tournament_wins(env, 500)\n",
    "                t += [wins[0]]\n",
    "        l_.append(np.mean(t))\n",
    "        c = sms.DescrStatsW(t).tconfint_mean()\n",
    "        s_.append((c[1]-c[0])/2)\n",
    "    w.append(l_)\n",
    "    s.append(s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49555556 0.52911111 0.741      0.98133333 0.254     ]\n",
      " [0.47       0.49666667 0.715      0.98       0.24266667]\n",
      " [0.23433333 0.281      0.491      0.832      0.148     ]\n",
      " [0.01266667 0.02866667 0.148      0.464      0.004     ]\n",
      " [0.72866667 0.74533333 0.846      0.984      0.478     ]]\n",
      "[[0.10442795 0.12936505 0.0778537  0.02500644 0.25892295]\n",
      " [0.11177977 0.0971628  0.08151352 0.01791337 0.31265943]\n",
      " [0.07821124 0.08939073 0.03970625 0.38118614 0.66072265]\n",
      " [0.01744801 0.00286844 0.22871169        nan        nan]\n",
      " [0.25378763 0.34386544 0.05082482        nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(w))\n",
    "print(np.array(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
